{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, ClassLabel\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from neo4j import GraphDatabase\n",
    "from utils import read_json\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whole_pdf(file_data):\n",
    "    whole_pdf = \"\"\n",
    "    for i in range(len(file_data)):\n",
    "        whole_pdf += file_data[i].page_content\n",
    "\n",
    "    return whole_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = read_json('configs.json')\n",
    "DATA_PATH = configs[\"DATA_PATH\"]\n",
    "DB_PATH = configs['DB_PATH']\n",
    "files_list = [file for file in os.listdir(DATA_PATH) if os.path.isfile(os.path.join(DATA_PATH, file))]\n",
    "\n",
    "def read_pdf(files_list, data_path=DATA_PATH):\n",
    "    content_dict = {}\n",
    "\n",
    "    for file_name in files_list:\n",
    "        file_path = data_path + file_name\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        content = loader.load()\n",
    "        whole_pdf = \"\"\n",
    "        for i in range(len(content)):\n",
    "            whole_pdf += content[i].page_content\n",
    "\n",
    "        whole_pdf = re.sub(r'[：。\\n]', '', whole_pdf)\n",
    "        content_dict[file_name] = whole_pdf\n",
    "\n",
    "    return content_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34944_高鐵_促參.pdf',\n",
       " '38005_核四_政策.pdf',\n",
       " '39243_核四_品質.pdf',\n",
       " '39477_核四_料件.pdf',\n",
       " '46365_高鐵_基金.pdf',\n",
       " '48052_大客車_逃生門.pdf',\n",
       " '48746_大客車_安全門.pdf',\n",
       " '49490_核四_延宕.pdf',\n",
       " '49627_核四_停建.pdf',\n",
       " '49676_大客車_駕照.pdf',\n",
       " '52922_大客車_超時.pdf',\n",
       " '54210_高鐵_出資.pdf',\n",
       " '54376_高鐵_航發.pdf',\n",
       " '54561_高鐵_機電.pdf',\n",
       " '58930_核四_封存.pdf']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_contents = read_pdf(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_extraction(input, pattern):\n",
    "\n",
    "    # Search using the pattern\n",
    "    match = re.search(pattern, input, re.S)\n",
    "\n",
    "    if match:\n",
    "        result = match.group(1).strip()  # Use strip() to remove any leading/trailing whitespace\n",
    "        print(\"Extraction succeed.\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n",
      "Extraction succeed.\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"貳、案   由(.*?)參、事實與理由\"\n",
    "\n",
    "extracted_content = {}\n",
    "for filename, content in pdf_contents.items():\n",
    "    extracted_content[filename] = content_extraction(content, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23382_高鐵_振動.pdf': None,\n",
       " '34944_高鐵_促參.pdf': '交通部於 87年間與臺灣高速鐵路公司簽訂「臺灣南北高速鐵路興建營運合約」及「臺灣南北高速鐵路站區開發合約 」，疏未預先審度該公司展延高鐵通車營運時程及遲延受領站區用地所生 損失之責任歸屬，並綢繆約定 相關處罰條款 ，嗣對政府權益保障恝置不察，一再同意該公司展延通車營運時程及受領站區用地， 致政府蒙受回饋金與租金收入減少及顧問費用增加等鉅額損失，均有違失，爰依監察法第 24條規定提案糾正',\n",
       " '38005_核四_政策.pdf': '核四封存後每年仍耗費數億元於資產維護管理，行政院及經濟部對外宣告核四重啟不可行，核四興建費用 2,833億元頇列為損失，行政院及 經濟部對核四政策之重大變動，導致資源嚴重浪費； 再者，經濟部宣布能源配比 (燃氣50%、燃煤30%、再生能源20%)之能源轉型政策，未經能源安全、能源經濟及環境影響等完整評估 ，復於再生能源發電量增加有限情況下， 以運轉中核電機組長期停機 方式減核 ，致近年火力發購電量逐年提高， 106年占比達84.4%，燃煤發電增幅 甚至高於燃氣，造成嚴重空氣污染；以及經濟部宣布 新能源政策 之前，並未評估其對電價之影響，迄 106年3月行政院始於國公營企業體檢小組會議評估 等情，均有違失，爰依法提案糾正',\n",
       " '39243_核四_品質.pdf': '台電公司 未落實「核四工程品質保證方案」，致龍門電廠試運轉時違規與注意改善事項層出不窮，如 抑壓池灌水作業 不當，致反應器廠房底層淹水 、壓力試驗合格之室內消防栓 系統，其 太平龍頭 竟脫落，致汽機廠房積水等 ，均嚴重衝擊國人對核能安全運轉之信心等情 ，確有諸多違失，爰依法提案糾正',\n",
       " '39477_核四_料件.pdf': '台灣電力股份有限公司 (下稱台電公司 )於本院調查核四廠一號機因施工測詴期間設備損壞而移用二號機相關設備之過程，所提供資料內容前後不一，設備組件損壞、採購及修復個數未能確實清查正確，顯見台電公司核四廠之料件管理系統紊亂，且回復本院公文一再發生資料正確性不足，核有怠失；另台電公司於 81年陳報核四興建計畫， 竟以69年所估算成本陳報， 未能如實報告核四建廠成本，致使政府無法確實評估該項投資計畫之成本效益，台電公司表示當時即考慮日後再以追加預算方式提出，此亦導致政 府長年來不得不對核四預算持續加碼，形成台電公司及國家之財務負擔，核有違失，爰依法提案糾正',\n",
       " '46365_高鐵_基金.pdf': '近年利率逐年下調， 資金成本下降， 惟交通部未督飭高公局利用此 改變趨勢而進行財務調度，積極規劃國道基金債務之舉新還舊，減輕利息 負擔，改善財務結構 ；該部復坐視國道基金之財務操作 受高鐵基金之影響；又該部迄今未將 國道基金負擔 未具自償性且與國道並無直接關聯之地區性道路興建支出，撥還該基金等情，均核有重大違失，爰依法提案糾正',\n",
       " '48052_大客車_逃生門.pdf': '交通部暨公路總局未善盡監督及執行車輛之監理機制，輕縱尊龍客運等公司違規變更內裝而危害公共安全，致生本案大客車六名乘客因逃生門遭鐵板封閉，無法開啟而慘遭大火燒死之重大事故，顯有違失，爰依監察法第二十四條之規定提案糾正',\n",
       " '48746_大客車_安全門.pdf': '交通部核准之安審（ 98）第1620號車型大客車，其檢測報告判定緊急出口符合法規，得於車輛靜止時由車內及車外徒手開啟，然105年7月19日（下稱0719）陸客團火燒車事故發生時卻因遊覽車左側安全門掛有鐵鍊並未即時開啟，其相同型式 20部車輛經查核亦逾八成於安全門裝置暗鎖，業嚴重威脅乘客逃生機會 ；又該部於核發車輛型式安全審驗合格證明書後，未善盡監督車身打造廠依法落實執行品質一致性管制計畫書，無法確保大客車之安全品質具有一致性 ；復漠視國內遊覽車業者為增設原廠設計所無之相關配備，擅自變更底盤電路系統，新核定之大客車電氣設備審驗補充作業規定 亦未包含使用中之舊車型大客車，恐難避免使用中之遊覽車車輛電路系統因加裝施工不良或過度負荷引發火災之可能性，造成人民生命財產之嚴重危害， 確有重大違失，爰依法提案糾正',\n",
       " '49490_核四_延宕.pdf': '台灣電力股份有限公司辦理核四計畫， 未採統包模式 ，衍生各類採購標案多達 835項，界面 整合困難， 且怠忽控管顧問公司工作內容，肇致服務費用暴增卻無法依約完成工作 ，又在未取得關鍵外購設備細部規格前，竟同意承商以假設數據先行設計，致到貨後頇 額外補償 修改變更費用 ，加上工地防颱應變失當等諸多違失，導致計畫執行效能不彰，進度嚴重落後，商轉日期一再展延逾 11年迄仍無著，工程經費更由新台幣 1,697億餘元暴增至 2,736億餘元，增幅超過 6成達1,039億餘元，且後續增加勢必難免，斲喪國家利益與政府形象；經濟部為核四計畫執行督導機關，長期粉飾計畫執行遭遇之瓶頸癥結，未能積極督飭台電公司有效因應妥處，恝置履約爭議及施工管理問題層出不窮，亦難辭怠忽監督之咎',\n",
       " '49627_核四_停建.pdf': '行政院貿然於 89年10月27日宣布停建進度已達33.81%之核四工程，又經濟部對於臺電公司三度函詢核四停建相關疑義，卻一再模糊虛應，恝置所屬無所適從，另臺電公司為迎合上意，未待上級正式函示或召開董事會應變，即由公司高層僅以口諭方式擅為傳達停建核四，並倉促發函指示廠商 不限期暫停契約執行，且核四工程未能採統包方式辦理，亦未有總顧問協助整合複雜之施工界面，導致工期延宕、預算追加、鉅額損失及品質安全疑慮等情事，其工期至少增加 44個月，且損失高達 1,870億元，未來核四是否安全運轉，屢遭質疑， 且現已逾核四計畫一號機展延後 之預訂商轉日期，惟尚未見修訂計畫期程， 行政院暨所屬經濟部、臺電公司等均難辭其咎',\n",
       " '49676_大客車_駕照.pdf': '交通部公路總局 辦理遊覽車客運業營運管理考核業務， 怠未督促所屬落實 各項表件查核勾稽職責，縱任 世通遊覽車客運股份有限公司 長期僱用無大客車職業駕駛執照者駕駛遊覽車，未 能及時查處 並責令改正，肇生101年5月9日花蓮太魯閣錦文橋旁翻車事故，嚴重危害旅運安全；且該局派赴事故現場人員，竟未查知該 翻覆遊覽車未依規定隨車攜帶駕駛人登記證、派車單及租車契約等資料，迨本院約詢通知責請說明後，始急洽業者查證屬實，並依違反汽車運輸業管理規則補行罰款，確有怠失，爰依法提案糾正',\n",
       " '52922_大客車_超時.pdf': '勞委會辦理公路客運業司機工時稽查，長久坐視超時工作之嚴重性，僅就稽查結果轉送各地勞政單位裁罰，對後續執行及改善措施未能落實追蹤管考，輕忽該行業攸關公眾安全之特性 ；交通部未能參酌先進國家對公路客運業合理駕駛時間之制訂，復未對近年因疲勞駕駛之肇禍事件深切檢討，以訂定公路客運業司機合理駕駛時間；公路總局於執行大客車駕駛審驗措施，未能記取近年發生多次公路客運業司機因個人健康因素，中斷行車任務之教訓，訂定妥適之健檢項目與標準 ，均核有違失',\n",
       " '54210_高鐵_出資.pdf': '行政院明知高鐵公司籌資不順，財務困難，投資風險極高，不但未能督促原始股東履行「政府零出資」承諾，反而 准予所屬公營事業機構、或實質上受其控制之公私合營公司或政府捐助財團法人將資金投入該公司一再挹注該公司鉅額資金 ，復提供鉅額中長期資金及融資保證，不但危及政府財政，並以公權力牽拖耗喪社會資材，嚴重悖離 BOT基本精神另中鋼公司投資高鐵公司特別股，該公司董事長林 ○○不但同時兼任高鐵公司董事，並三次主導投資高鐵公司特別股，立場偏失，主管機關皆怠忽不察；中技社投資高鐵公司特別股，既不合原捐助目的及章程規定，且程序上亦有重大瑕疵，復影響該社財務資金運用甚鉅，主管機關經濟部皆恝置不理又 財政部甫 修正相關法令，各公營及公私 合營行庫旋即投資高鐵公司計一百七十三億元，招致非議；公營行庫將上開投資不當認列為短期投資，不僅傷及公營行庫財務表達之正確性，且得以短期投資拖延補辦預算之程序；高鐵公司財務狀況日趨惡化，政府財務擔保風險持續升高，交通部長期視若無睹，粉飾太帄，徒增政府財務風險，均有重大違失 ，爰依法提案糾正',\n",
       " '54376_高鐵_航發.pdf': '行政院為協助解決臺灣高速鐵路公司 (下稱高鐵公司 )資金需求，指示中華航空事業發展基金會 (下稱航發會 )限期購買該公司丙種特別股新臺幣 (下同 )四十五億元，惟該項投資決策未經正式會議及評估作業，亦未留存任何紀錄可供稽查，過程粗糙急率；又該院明知航發會屬財團法人，投資高速鐵路有違該會 協助發展航空事業之章程目的，亦可知悉因時間急迫，相關董事會召集程序勢難符合法令規定，仍為上開違反章程及法令之指示，顯有失當；而交通部長擔任航發會董事長，管理及監督財團法人之角色混同，董事會以遵守政策指示及考量國家利益為由通過相關議案，交通部復怠於監督，率予許可，致生航發會重大損害，財團法人設置之公益目的盪然無存，爰依法提案糾正',\n",
       " '54561_高鐵_機電.pdf': '交通部及所屬高速鐵路工程局 率爾同意 變更機電核心系統，致 台灣高鐵淪為歐、日混血系統，每百萬公里發生之行車事故件數，較日本新幹線高出甚多，迄未深入檢討等情，爰依法提案糾正',\n",
       " '58930_核四_封存.pdf': '我國核能安全監管機關為行政院原子能委員會，核四未經該會完整審查認可，未符合核能安全要求 下，經濟部卻以核四安檢過關，使部分民眾認 為核四安全已由經濟部審查掛保證通過， 積非成是，影響迄今；而核四封存前， 未能解決 諸多系統 之設計及設備問題，即使當時並未封存、繼續詴運轉下去，仍有安全疑慮， 在外界對於核四重啟見解不一之際， 經濟部反而提供錯誤訊息 ，導致核四紛擾不斷又，台電未能及時監督承商， 現因核四斷層新事證，更加劇後續處理之困難度，台電對核能安全與核四品質把關 之相關作為，確實不夠嚴謹， 經濟部及台電均 核有怠失，爰依法提案糾正'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_label(filename):\n",
    "    # Assuming the label is always after the first underscore and ends before the second underscore\n",
    "    match = re.search(r'_(.*?)_', filename)\n",
    "    if match:\n",
    "        return match.group(1)  # This extracts text between the first pair of underscores\n",
    "    return None  # In case the pattern does not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '高鐵', 'text': None},\n",
       " {'label': '高鐵',\n",
       "  'text': '交通部於 87年間與臺灣高速鐵路公司簽訂「臺灣南北高速鐵路興建營運合約」及「臺灣南北高速鐵路站區開發合約 」，疏未預先審度該公司展延高鐵通車營運時程及遲延受領站區用地所生 損失之責任歸屬，並綢繆約定 相關處罰條款 ，嗣對政府權益保障恝置不察，一再同意該公司展延通車營運時程及受領站區用地， 致政府蒙受回饋金與租金收入減少及顧問費用增加等鉅額損失，均有違失，爰依監察法第 24條規定提案糾正'},\n",
       " {'label': '核四',\n",
       "  'text': '核四封存後每年仍耗費數億元於資產維護管理，行政院及經濟部對外宣告核四重啟不可行，核四興建費用 2,833億元頇列為損失，行政院及 經濟部對核四政策之重大變動，導致資源嚴重浪費； 再者，經濟部宣布能源配比 (燃氣50%、燃煤30%、再生能源20%)之能源轉型政策，未經能源安全、能源經濟及環境影響等完整評估 ，復於再生能源發電量增加有限情況下， 以運轉中核電機組長期停機 方式減核 ，致近年火力發購電量逐年提高， 106年占比達84.4%，燃煤發電增幅 甚至高於燃氣，造成嚴重空氣污染；以及經濟部宣布 新能源政策 之前，並未評估其對電價之影響，迄 106年3月行政院始於國公營企業體檢小組會議評估 等情，均有違失，爰依法提案糾正'},\n",
       " {'label': '核四',\n",
       "  'text': '台電公司 未落實「核四工程品質保證方案」，致龍門電廠試運轉時違規與注意改善事項層出不窮，如 抑壓池灌水作業 不當，致反應器廠房底層淹水 、壓力試驗合格之室內消防栓 系統，其 太平龍頭 竟脫落，致汽機廠房積水等 ，均嚴重衝擊國人對核能安全運轉之信心等情 ，確有諸多違失，爰依法提案糾正'},\n",
       " {'label': '核四',\n",
       "  'text': '台灣電力股份有限公司 (下稱台電公司 )於本院調查核四廠一號機因施工測詴期間設備損壞而移用二號機相關設備之過程，所提供資料內容前後不一，設備組件損壞、採購及修復個數未能確實清查正確，顯見台電公司核四廠之料件管理系統紊亂，且回復本院公文一再發生資料正確性不足，核有怠失；另台電公司於 81年陳報核四興建計畫， 竟以69年所估算成本陳報， 未能如實報告核四建廠成本，致使政府無法確實評估該項投資計畫之成本效益，台電公司表示當時即考慮日後再以追加預算方式提出，此亦導致政 府長年來不得不對核四預算持續加碼，形成台電公司及國家之財務負擔，核有違失，爰依法提案糾正'},\n",
       " {'label': '高鐵',\n",
       "  'text': '近年利率逐年下調， 資金成本下降， 惟交通部未督飭高公局利用此 改變趨勢而進行財務調度，積極規劃國道基金債務之舉新還舊，減輕利息 負擔，改善財務結構 ；該部復坐視國道基金之財務操作 受高鐵基金之影響；又該部迄今未將 國道基金負擔 未具自償性且與國道並無直接關聯之地區性道路興建支出，撥還該基金等情，均核有重大違失，爰依法提案糾正'},\n",
       " {'label': '大客車',\n",
       "  'text': '交通部暨公路總局未善盡監督及執行車輛之監理機制，輕縱尊龍客運等公司違規變更內裝而危害公共安全，致生本案大客車六名乘客因逃生門遭鐵板封閉，無法開啟而慘遭大火燒死之重大事故，顯有違失，爰依監察法第二十四條之規定提案糾正'},\n",
       " {'label': '大客車',\n",
       "  'text': '交通部核准之安審（ 98）第1620號車型大客車，其檢測報告判定緊急出口符合法規，得於車輛靜止時由車內及車外徒手開啟，然105年7月19日（下稱0719）陸客團火燒車事故發生時卻因遊覽車左側安全門掛有鐵鍊並未即時開啟，其相同型式 20部車輛經查核亦逾八成於安全門裝置暗鎖，業嚴重威脅乘客逃生機會 ；又該部於核發車輛型式安全審驗合格證明書後，未善盡監督車身打造廠依法落實執行品質一致性管制計畫書，無法確保大客車之安全品質具有一致性 ；復漠視國內遊覽車業者為增設原廠設計所無之相關配備，擅自變更底盤電路系統，新核定之大客車電氣設備審驗補充作業規定 亦未包含使用中之舊車型大客車，恐難避免使用中之遊覽車車輛電路系統因加裝施工不良或過度負荷引發火災之可能性，造成人民生命財產之嚴重危害， 確有重大違失，爰依法提案糾正'},\n",
       " {'label': '核四',\n",
       "  'text': '台灣電力股份有限公司辦理核四計畫， 未採統包模式 ，衍生各類採購標案多達 835項，界面 整合困難， 且怠忽控管顧問公司工作內容，肇致服務費用暴增卻無法依約完成工作 ，又在未取得關鍵外購設備細部規格前，竟同意承商以假設數據先行設計，致到貨後頇 額外補償 修改變更費用 ，加上工地防颱應變失當等諸多違失，導致計畫執行效能不彰，進度嚴重落後，商轉日期一再展延逾 11年迄仍無著，工程經費更由新台幣 1,697億餘元暴增至 2,736億餘元，增幅超過 6成達1,039億餘元，且後續增加勢必難免，斲喪國家利益與政府形象；經濟部為核四計畫執行督導機關，長期粉飾計畫執行遭遇之瓶頸癥結，未能積極督飭台電公司有效因應妥處，恝置履約爭議及施工管理問題層出不窮，亦難辭怠忽監督之咎'},\n",
       " {'label': '核四',\n",
       "  'text': '行政院貿然於 89年10月27日宣布停建進度已達33.81%之核四工程，又經濟部對於臺電公司三度函詢核四停建相關疑義，卻一再模糊虛應，恝置所屬無所適從，另臺電公司為迎合上意，未待上級正式函示或召開董事會應變，即由公司高層僅以口諭方式擅為傳達停建核四，並倉促發函指示廠商 不限期暫停契約執行，且核四工程未能採統包方式辦理，亦未有總顧問協助整合複雜之施工界面，導致工期延宕、預算追加、鉅額損失及品質安全疑慮等情事，其工期至少增加 44個月，且損失高達 1,870億元，未來核四是否安全運轉，屢遭質疑， 且現已逾核四計畫一號機展延後 之預訂商轉日期，惟尚未見修訂計畫期程， 行政院暨所屬經濟部、臺電公司等均難辭其咎'},\n",
       " {'label': '大客車',\n",
       "  'text': '交通部公路總局 辦理遊覽車客運業營運管理考核業務， 怠未督促所屬落實 各項表件查核勾稽職責，縱任 世通遊覽車客運股份有限公司 長期僱用無大客車職業駕駛執照者駕駛遊覽車，未 能及時查處 並責令改正，肇生101年5月9日花蓮太魯閣錦文橋旁翻車事故，嚴重危害旅運安全；且該局派赴事故現場人員，竟未查知該 翻覆遊覽車未依規定隨車攜帶駕駛人登記證、派車單及租車契約等資料，迨本院約詢通知責請說明後，始急洽業者查證屬實，並依違反汽車運輸業管理規則補行罰款，確有怠失，爰依法提案糾正'},\n",
       " {'label': '大客車',\n",
       "  'text': '勞委會辦理公路客運業司機工時稽查，長久坐視超時工作之嚴重性，僅就稽查結果轉送各地勞政單位裁罰，對後續執行及改善措施未能落實追蹤管考，輕忽該行業攸關公眾安全之特性 ；交通部未能參酌先進國家對公路客運業合理駕駛時間之制訂，復未對近年因疲勞駕駛之肇禍事件深切檢討，以訂定公路客運業司機合理駕駛時間；公路總局於執行大客車駕駛審驗措施，未能記取近年發生多次公路客運業司機因個人健康因素，中斷行車任務之教訓，訂定妥適之健檢項目與標準 ，均核有違失'},\n",
       " {'label': '高鐵',\n",
       "  'text': '行政院明知高鐵公司籌資不順，財務困難，投資風險極高，不但未能督促原始股東履行「政府零出資」承諾，反而 准予所屬公營事業機構、或實質上受其控制之公私合營公司或政府捐助財團法人將資金投入該公司一再挹注該公司鉅額資金 ，復提供鉅額中長期資金及融資保證，不但危及政府財政，並以公權力牽拖耗喪社會資材，嚴重悖離 BOT基本精神另中鋼公司投資高鐵公司特別股，該公司董事長林 ○○不但同時兼任高鐵公司董事，並三次主導投資高鐵公司特別股，立場偏失，主管機關皆怠忽不察；中技社投資高鐵公司特別股，既不合原捐助目的及章程規定，且程序上亦有重大瑕疵，復影響該社財務資金運用甚鉅，主管機關經濟部皆恝置不理又 財政部甫 修正相關法令，各公營及公私 合營行庫旋即投資高鐵公司計一百七十三億元，招致非議；公營行庫將上開投資不當認列為短期投資，不僅傷及公營行庫財務表達之正確性，且得以短期投資拖延補辦預算之程序；高鐵公司財務狀況日趨惡化，政府財務擔保風險持續升高，交通部長期視若無睹，粉飾太帄，徒增政府財務風險，均有重大違失 ，爰依法提案糾正'},\n",
       " {'label': '高鐵',\n",
       "  'text': '行政院為協助解決臺灣高速鐵路公司 (下稱高鐵公司 )資金需求，指示中華航空事業發展基金會 (下稱航發會 )限期購買該公司丙種特別股新臺幣 (下同 )四十五億元，惟該項投資決策未經正式會議及評估作業，亦未留存任何紀錄可供稽查，過程粗糙急率；又該院明知航發會屬財團法人，投資高速鐵路有違該會 協助發展航空事業之章程目的，亦可知悉因時間急迫，相關董事會召集程序勢難符合法令規定，仍為上開違反章程及法令之指示，顯有失當；而交通部長擔任航發會董事長，管理及監督財團法人之角色混同，董事會以遵守政策指示及考量國家利益為由通過相關議案，交通部復怠於監督，率予許可，致生航發會重大損害，財團法人設置之公益目的盪然無存，爰依法提案糾正'},\n",
       " {'label': '高鐵',\n",
       "  'text': '交通部及所屬高速鐵路工程局 率爾同意 變更機電核心系統，致 台灣高鐵淪為歐、日混血系統，每百萬公里發生之行車事故件數，較日本新幹線高出甚多，迄未深入檢討等情，爰依法提案糾正'},\n",
       " {'label': '核四',\n",
       "  'text': '我國核能安全監管機關為行政院原子能委員會，核四未經該會完整審查認可，未符合核能安全要求 下，經濟部卻以核四安檢過關，使部分民眾認 為核四安全已由經濟部審查掛保證通過， 積非成是，影響迄今；而核四封存前， 未能解決 諸多系統 之設計及設備問題，即使當時並未封存、繼續詴運轉下去，仍有安全疑慮， 在外界對於核四重啟見解不一之際， 經濟部反而提供錯誤訊息 ，導致核四紛擾不斷又，台電未能及時監督承商， 現因核四斷層新事證，更加劇後續處理之困難度，台電對核能安全與核四品質把關 之相關作為，確實不夠嚴謹， 經濟部及台電均 核有怠失，爰依法提案糾正'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data  = [{'label': extract_label(filename), 'text' : content } for filename, content in extracted_content.items()]\n",
    "formatted_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['高鐵', '核四', '大客車'], id=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = []\n",
    "for i in range(len(formatted_data)):\n",
    "    current_label = formatted_data[i]['label']\n",
    "    if current_label not in label:\n",
    "        label.append(current_label)\n",
    "    else:\n",
    "        continue\n",
    "label_feature = ClassLabel(names=label)\n",
    "label_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({\n",
    "    'text': [item['text'] for item in formatted_data],\n",
    "    'label': [item['label'] for item in formatted_data]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label(example):\n",
    "    \n",
    "    example['label'] = [label_feature.str2int(label) for label in example['label']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e33a38416924090b58234fd1be04b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_processed = dataset.map(preprocess_label, batched=True)\n",
    "dataset_split = dataset_processed.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 11\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-transformers/all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m前天是禮拜二\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m昨天是禮拜二\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(sentences, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m encoded_input\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = ['前天是禮拜二', '昨天是禮拜二']\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92570424]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sentence_embeddings[0].reshape(1, -1), sentence_embeddings[1].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dict = {}\n",
    "for filename, content in extracted_content.items():\n",
    "    encoded_content = tokenizer(content, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.inference_mode():\n",
    "        model_output = model(**encoded_content)\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_content['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    tokenized_dict[filename] = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.DataFrame(index=tokenized_dict.keys(), columns=tokenized_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "similarity_df = pd.DataFrame(index=tokenized_dict.keys(), columns=tokenized_dict.keys())\n",
    "\n",
    "# Calculate cosine similarity between each pair of vectors\n",
    "for name1, vec1 in tokenized_dict.items():\n",
    "    for name2, vec2 in tokenized_dict.items():\n",
    "        similarity_df.loc[name1, name2] = cosine_similarity(vec1, vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>34944_高鐵_促參.pdf</th>\n",
       "      <th>38005_核四_政策.pdf</th>\n",
       "      <th>39243_核四_品質.pdf</th>\n",
       "      <th>39477_核四_料件.pdf</th>\n",
       "      <th>46365_高鐵_基金.pdf</th>\n",
       "      <th>48052_大客車_逃生門.pdf</th>\n",
       "      <th>48746_大客車_安全門.pdf</th>\n",
       "      <th>49490_核四_延宕.pdf</th>\n",
       "      <th>49627_核四_停建.pdf</th>\n",
       "      <th>49676_大客車_駕照.pdf</th>\n",
       "      <th>52922_大客車_超時.pdf</th>\n",
       "      <th>54210_高鐵_出資.pdf</th>\n",
       "      <th>54376_高鐵_航發.pdf</th>\n",
       "      <th>54561_高鐵_機電.pdf</th>\n",
       "      <th>58930_核四_封存.pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34944_高鐵_促參.pdf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771646</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.810293</td>\n",
       "      <td>0.757769</td>\n",
       "      <td>0.724102</td>\n",
       "      <td>0.737007</td>\n",
       "      <td>0.831104</td>\n",
       "      <td>0.843057</td>\n",
       "      <td>0.820516</td>\n",
       "      <td>0.881772</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.81963</td>\n",
       "      <td>0.696251</td>\n",
       "      <td>0.693054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38005_核四_政策.pdf</th>\n",
       "      <td>0.771646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5546</td>\n",
       "      <td>0.769547</td>\n",
       "      <td>0.676038</td>\n",
       "      <td>0.573962</td>\n",
       "      <td>0.77681</td>\n",
       "      <td>0.841877</td>\n",
       "      <td>0.869432</td>\n",
       "      <td>0.682205</td>\n",
       "      <td>0.759324</td>\n",
       "      <td>0.786793</td>\n",
       "      <td>0.833689</td>\n",
       "      <td>0.545257</td>\n",
       "      <td>0.829629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243_核四_品質.pdf</th>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.5546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638359</td>\n",
       "      <td>0.575538</td>\n",
       "      <td>0.738709</td>\n",
       "      <td>0.514832</td>\n",
       "      <td>0.668872</td>\n",
       "      <td>0.666733</td>\n",
       "      <td>0.613016</td>\n",
       "      <td>0.701931</td>\n",
       "      <td>0.53878</td>\n",
       "      <td>0.608017</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.52084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39477_核四_料件.pdf</th>\n",
       "      <td>0.810293</td>\n",
       "      <td>0.769547</td>\n",
       "      <td>0.638359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569365</td>\n",
       "      <td>0.558339</td>\n",
       "      <td>0.700211</td>\n",
       "      <td>0.87964</td>\n",
       "      <td>0.864525</td>\n",
       "      <td>0.762747</td>\n",
       "      <td>0.870343</td>\n",
       "      <td>0.848424</td>\n",
       "      <td>0.852757</td>\n",
       "      <td>0.476027</td>\n",
       "      <td>0.704625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46365_高鐵_基金.pdf</th>\n",
       "      <td>0.757769</td>\n",
       "      <td>0.676038</td>\n",
       "      <td>0.575538</td>\n",
       "      <td>0.569365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562911</td>\n",
       "      <td>0.567731</td>\n",
       "      <td>0.649495</td>\n",
       "      <td>0.647114</td>\n",
       "      <td>0.580461</td>\n",
       "      <td>0.615131</td>\n",
       "      <td>0.614591</td>\n",
       "      <td>0.653924</td>\n",
       "      <td>0.599685</td>\n",
       "      <td>0.605182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48052_大客車_逃生門.pdf</th>\n",
       "      <td>0.724102</td>\n",
       "      <td>0.573962</td>\n",
       "      <td>0.738709</td>\n",
       "      <td>0.558339</td>\n",
       "      <td>0.562911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66724</td>\n",
       "      <td>0.631306</td>\n",
       "      <td>0.607808</td>\n",
       "      <td>0.745443</td>\n",
       "      <td>0.694181</td>\n",
       "      <td>0.489822</td>\n",
       "      <td>0.543012</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>0.499585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48746_大客車_安全門.pdf</th>\n",
       "      <td>0.737007</td>\n",
       "      <td>0.77681</td>\n",
       "      <td>0.514832</td>\n",
       "      <td>0.700211</td>\n",
       "      <td>0.567731</td>\n",
       "      <td>0.66724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783596</td>\n",
       "      <td>0.730051</td>\n",
       "      <td>0.839712</td>\n",
       "      <td>0.767071</td>\n",
       "      <td>0.732613</td>\n",
       "      <td>0.744173</td>\n",
       "      <td>0.559655</td>\n",
       "      <td>0.742649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49490_核四_延宕.pdf</th>\n",
       "      <td>0.831104</td>\n",
       "      <td>0.841877</td>\n",
       "      <td>0.668872</td>\n",
       "      <td>0.87964</td>\n",
       "      <td>0.649495</td>\n",
       "      <td>0.631306</td>\n",
       "      <td>0.783596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913284</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.870392</td>\n",
       "      <td>0.842519</td>\n",
       "      <td>0.865204</td>\n",
       "      <td>0.556715</td>\n",
       "      <td>0.786616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49627_核四_停建.pdf</th>\n",
       "      <td>0.843057</td>\n",
       "      <td>0.869432</td>\n",
       "      <td>0.666733</td>\n",
       "      <td>0.864525</td>\n",
       "      <td>0.647114</td>\n",
       "      <td>0.607808</td>\n",
       "      <td>0.730051</td>\n",
       "      <td>0.913284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740321</td>\n",
       "      <td>0.842977</td>\n",
       "      <td>0.853902</td>\n",
       "      <td>0.885557</td>\n",
       "      <td>0.599092</td>\n",
       "      <td>0.808137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49676_大客車_駕照.pdf</th>\n",
       "      <td>0.820516</td>\n",
       "      <td>0.682205</td>\n",
       "      <td>0.613016</td>\n",
       "      <td>0.762747</td>\n",
       "      <td>0.580461</td>\n",
       "      <td>0.745443</td>\n",
       "      <td>0.839712</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.740321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.707834</td>\n",
       "      <td>0.727746</td>\n",
       "      <td>0.638968</td>\n",
       "      <td>0.687937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52922_大客車_超時.pdf</th>\n",
       "      <td>0.881772</td>\n",
       "      <td>0.759324</td>\n",
       "      <td>0.701931</td>\n",
       "      <td>0.870343</td>\n",
       "      <td>0.615131</td>\n",
       "      <td>0.694181</td>\n",
       "      <td>0.767071</td>\n",
       "      <td>0.870392</td>\n",
       "      <td>0.842977</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829786</td>\n",
       "      <td>0.835373</td>\n",
       "      <td>0.601635</td>\n",
       "      <td>0.679446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54210_高鐵_出資.pdf</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.786793</td>\n",
       "      <td>0.53878</td>\n",
       "      <td>0.848424</td>\n",
       "      <td>0.614591</td>\n",
       "      <td>0.489822</td>\n",
       "      <td>0.732613</td>\n",
       "      <td>0.842519</td>\n",
       "      <td>0.853902</td>\n",
       "      <td>0.707834</td>\n",
       "      <td>0.829786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.487889</td>\n",
       "      <td>0.696772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54376_高鐵_航發.pdf</th>\n",
       "      <td>0.81963</td>\n",
       "      <td>0.833689</td>\n",
       "      <td>0.608017</td>\n",
       "      <td>0.852757</td>\n",
       "      <td>0.653924</td>\n",
       "      <td>0.543012</td>\n",
       "      <td>0.744173</td>\n",
       "      <td>0.865204</td>\n",
       "      <td>0.885557</td>\n",
       "      <td>0.727746</td>\n",
       "      <td>0.835373</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.539263</td>\n",
       "      <td>0.739105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54561_高鐵_機電.pdf</th>\n",
       "      <td>0.696251</td>\n",
       "      <td>0.545257</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.476027</td>\n",
       "      <td>0.599685</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>0.559655</td>\n",
       "      <td>0.556715</td>\n",
       "      <td>0.599092</td>\n",
       "      <td>0.638968</td>\n",
       "      <td>0.601635</td>\n",
       "      <td>0.487889</td>\n",
       "      <td>0.539263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.51256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58930_核四_封存.pdf</th>\n",
       "      <td>0.693054</td>\n",
       "      <td>0.829629</td>\n",
       "      <td>0.52084</td>\n",
       "      <td>0.704625</td>\n",
       "      <td>0.605182</td>\n",
       "      <td>0.499585</td>\n",
       "      <td>0.742649</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.808137</td>\n",
       "      <td>0.687937</td>\n",
       "      <td>0.679446</td>\n",
       "      <td>0.696772</td>\n",
       "      <td>0.739105</td>\n",
       "      <td>0.51256</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  34944_高鐵_促參.pdf 38005_核四_政策.pdf 39243_核四_品質.pdf  \\\n",
       "34944_高鐵_促參.pdf               1.0        0.771646        0.715157   \n",
       "38005_核四_政策.pdf          0.771646             1.0          0.5546   \n",
       "39243_核四_品質.pdf          0.715157          0.5546             1.0   \n",
       "39477_核四_料件.pdf          0.810293        0.769547        0.638359   \n",
       "46365_高鐵_基金.pdf          0.757769        0.676038        0.575538   \n",
       "48052_大客車_逃生門.pdf        0.724102        0.573962        0.738709   \n",
       "48746_大客車_安全門.pdf        0.737007         0.77681        0.514832   \n",
       "49490_核四_延宕.pdf          0.831104        0.841877        0.668872   \n",
       "49627_核四_停建.pdf          0.843057        0.869432        0.666733   \n",
       "49676_大客車_駕照.pdf         0.820516        0.682205        0.613016   \n",
       "52922_大客車_超時.pdf         0.881772        0.759324        0.701931   \n",
       "54210_高鐵_出資.pdf             0.808        0.786793         0.53878   \n",
       "54376_高鐵_航發.pdf           0.81963        0.833689        0.608017   \n",
       "54561_高鐵_機電.pdf          0.696251        0.545257        0.680304   \n",
       "58930_核四_封存.pdf          0.693054        0.829629         0.52084   \n",
       "\n",
       "                  39477_核四_料件.pdf 46365_高鐵_基金.pdf 48052_大客車_逃生門.pdf  \\\n",
       "34944_高鐵_促參.pdf          0.810293        0.757769          0.724102   \n",
       "38005_核四_政策.pdf          0.769547        0.676038          0.573962   \n",
       "39243_核四_品質.pdf          0.638359        0.575538          0.738709   \n",
       "39477_核四_料件.pdf               1.0        0.569365          0.558339   \n",
       "46365_高鐵_基金.pdf          0.569365             1.0          0.562911   \n",
       "48052_大客車_逃生門.pdf        0.558339        0.562911               1.0   \n",
       "48746_大客車_安全門.pdf        0.700211        0.567731           0.66724   \n",
       "49490_核四_延宕.pdf           0.87964        0.649495          0.631306   \n",
       "49627_核四_停建.pdf          0.864525        0.647114          0.607808   \n",
       "49676_大客車_駕照.pdf         0.762747        0.580461          0.745443   \n",
       "52922_大客車_超時.pdf         0.870343        0.615131          0.694181   \n",
       "54210_高鐵_出資.pdf          0.848424        0.614591          0.489822   \n",
       "54376_高鐵_航發.pdf          0.852757        0.653924          0.543012   \n",
       "54561_高鐵_機電.pdf          0.476027        0.599685          0.774908   \n",
       "58930_核四_封存.pdf          0.704625        0.605182          0.499585   \n",
       "\n",
       "                  48746_大客車_安全門.pdf 49490_核四_延宕.pdf 49627_核四_停建.pdf  \\\n",
       "34944_高鐵_促參.pdf            0.737007        0.831104        0.843057   \n",
       "38005_核四_政策.pdf             0.77681        0.841877        0.869432   \n",
       "39243_核四_品質.pdf            0.514832        0.668872        0.666733   \n",
       "39477_核四_料件.pdf            0.700211         0.87964        0.864525   \n",
       "46365_高鐵_基金.pdf            0.567731        0.649495        0.647114   \n",
       "48052_大客車_逃生門.pdf           0.66724        0.631306        0.607808   \n",
       "48746_大客車_安全門.pdf               1.0        0.783596        0.730051   \n",
       "49490_核四_延宕.pdf            0.783596             1.0        0.913284   \n",
       "49627_核四_停建.pdf            0.730051        0.913284             1.0   \n",
       "49676_大客車_駕照.pdf           0.839712        0.808667        0.740321   \n",
       "52922_大客車_超時.pdf           0.767071        0.870392        0.842977   \n",
       "54210_高鐵_出資.pdf            0.732613        0.842519        0.853902   \n",
       "54376_高鐵_航發.pdf            0.744173        0.865204        0.885557   \n",
       "54561_高鐵_機電.pdf            0.559655        0.556715        0.599092   \n",
       "58930_核四_封存.pdf            0.742649        0.786616        0.808137   \n",
       "\n",
       "                  49676_大客車_駕照.pdf 52922_大客車_超時.pdf 54210_高鐵_出資.pdf  \\\n",
       "34944_高鐵_促參.pdf           0.820516         0.881772           0.808   \n",
       "38005_核四_政策.pdf           0.682205         0.759324        0.786793   \n",
       "39243_核四_品質.pdf           0.613016         0.701931         0.53878   \n",
       "39477_核四_料件.pdf           0.762747         0.870343        0.848424   \n",
       "46365_高鐵_基金.pdf           0.580461         0.615131        0.614591   \n",
       "48052_大客車_逃生門.pdf         0.745443         0.694181        0.489822   \n",
       "48746_大客車_安全門.pdf         0.839712         0.767071        0.732613   \n",
       "49490_核四_延宕.pdf           0.808667         0.870392        0.842519   \n",
       "49627_核四_停建.pdf           0.740321         0.842977        0.853902   \n",
       "49676_大客車_駕照.pdf               1.0         0.841511        0.707834   \n",
       "52922_大客車_超時.pdf          0.841511              1.0        0.829786   \n",
       "54210_高鐵_出資.pdf           0.707834         0.829786             1.0   \n",
       "54376_高鐵_航發.pdf           0.727746         0.835373        0.905333   \n",
       "54561_高鐵_機電.pdf           0.638968         0.601635        0.487889   \n",
       "58930_核四_封存.pdf           0.687937         0.679446        0.696772   \n",
       "\n",
       "                  54376_高鐵_航發.pdf 54561_高鐵_機電.pdf 58930_核四_封存.pdf  \n",
       "34944_高鐵_促參.pdf           0.81963        0.696251        0.693054  \n",
       "38005_核四_政策.pdf          0.833689        0.545257        0.829629  \n",
       "39243_核四_品質.pdf          0.608017        0.680304         0.52084  \n",
       "39477_核四_料件.pdf          0.852757        0.476027        0.704625  \n",
       "46365_高鐵_基金.pdf          0.653924        0.599685        0.605182  \n",
       "48052_大客車_逃生門.pdf        0.543012        0.774908        0.499585  \n",
       "48746_大客車_安全門.pdf        0.744173        0.559655        0.742649  \n",
       "49490_核四_延宕.pdf          0.865204        0.556715        0.786616  \n",
       "49627_核四_停建.pdf          0.885557        0.599092        0.808137  \n",
       "49676_大客車_駕照.pdf         0.727746        0.638968        0.687937  \n",
       "52922_大客車_超時.pdf         0.835373        0.601635        0.679446  \n",
       "54210_高鐵_出資.pdf          0.905333        0.487889        0.696772  \n",
       "54376_高鐵_航發.pdf               1.0        0.539263        0.739105  \n",
       "54561_高鐵_機電.pdf          0.539263             1.0         0.51256  \n",
       "58930_核四_封存.pdf          0.739105         0.51256             1.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distilbert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModel\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"distilbert-base-multilingual-cased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_ckpt, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() \n",
    "              if k in tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 11\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9b6c93917c426f951c996a88434c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_split\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\dataset_dict.py:869\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 869\u001b[0m     {\n\u001b[0;32m    870\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    871\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m    872\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[0;32m    873\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[0;32m    874\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[0;32m    875\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[0;32m    876\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    877\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    878\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[0;32m    879\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    880\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    881\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    882\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    883\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    884\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[0;32m    885\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[0;32m    886\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[0;32m    887\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[0;32m    888\u001b[0m         )\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    890\u001b[0m     }\n\u001b[0;32m    891\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\dataset_dict.py:870\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    869\u001b[0m     {\n\u001b[1;32m--> 870\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    890\u001b[0m     }\n\u001b[0;32m    891\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    565\u001b[0m }\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3158\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3543\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3544\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3545\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3547\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3556\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\datasets\\arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3420\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(batch):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2858\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2857\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2858\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2944\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2940\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2941\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2942\u001b[0m         )\n\u001b[0;32m   2943\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2945\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2946\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2947\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2948\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2949\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2950\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2951\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2952\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2953\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2954\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2955\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2956\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2957\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2958\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2959\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2960\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2961\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2962\u001b[0m     )\n\u001b[0;32m   2963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2965\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2966\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2982\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2983\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3135\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3126\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3127\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3128\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3132\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3133\u001b[0m )\n\u001b[1;32m-> 3135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   3136\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3137\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3138\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3139\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3140\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3141\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3142\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3143\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3144\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3145\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3146\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3147\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3148\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3149\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3150\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3151\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3153\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\transformers\\tokenization_utils.py:803\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m--> 803\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    805\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\supervisor_llm\\lib\\site-packages\\transformers\\tokenization_utils.py:783\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "dataset_encoded = dataset_split.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.set_format(\"torch\", \n",
    "                            columns=[\"input_ids\",  \"label\",\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    label = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(label, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(label, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91301f6f02b641e285eec853f6d7d118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1103, 'grad_norm': 8.735570907592773, 'learning_rate': 1.9e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c993abd433b40e9ad68c80aa6cf5b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0666906833648682, 'eval_accuracy': 0.4, 'eval_f1': 0.22857142857142856, 'eval_runtime': 1.3192, 'eval_samples_per_second': 3.79, 'eval_steps_per_second': 3.79, 'epoch': 1.0}\n",
      "{'loss': 1.1276, 'grad_norm': 8.09397029876709, 'learning_rate': 1.8e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c0708175784d87b848ca0ea24baf72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.074120283126831, 'eval_accuracy': 0.4, 'eval_f1': 0.22857142857142856, 'eval_runtime': 1.6209, 'eval_samples_per_second': 3.085, 'eval_steps_per_second': 3.085, 'epoch': 2.0}\n",
      "{'loss': 1.1235, 'grad_norm': 7.93947172164917, 'learning_rate': 1.7e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5827556f165642769cd32f84c42baaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.064603567123413, 'eval_accuracy': 0.4, 'eval_f1': 0.22857142857142856, 'eval_runtime': 1.5624, 'eval_samples_per_second': 3.2, 'eval_steps_per_second': 3.2, 'epoch': 3.0}\n",
      "{'loss': 1.0609, 'grad_norm': 6.224499702453613, 'learning_rate': 1.6000000000000003e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f5212a731a4dd78553dd98441b4668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0581352710723877, 'eval_accuracy': 0.4, 'eval_f1': 0.22857142857142856, 'eval_runtime': 1.5601, 'eval_samples_per_second': 3.205, 'eval_steps_per_second': 3.205, 'epoch': 4.0}\n",
      "{'loss': 1.0832, 'grad_norm': 8.894120216369629, 'learning_rate': 1.5000000000000002e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29af1577bbb945d7ace7811832935914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.017627477645874, 'eval_accuracy': 0.4, 'eval_f1': 0.22857142857142856, 'eval_runtime': 1.6181, 'eval_samples_per_second': 3.09, 'eval_steps_per_second': 3.09, 'epoch': 5.0}\n",
      "{'loss': 0.9636, 'grad_norm': 6.795644760131836, 'learning_rate': 1.4e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df4bee27a0b41b9adbde229fd722ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.940122127532959, 'eval_accuracy': 0.4, 'eval_f1': 0.22857142857142856, 'eval_runtime': 1.5618, 'eval_samples_per_second': 3.201, 'eval_steps_per_second': 3.201, 'epoch': 6.0}\n",
      "{'loss': 0.8234, 'grad_norm': 9.339310646057129, 'learning_rate': 1.3000000000000001e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccf17c206a04ed9a3fd9d847ffcebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.811183750629425, 'eval_accuracy': 0.8, 'eval_f1': 0.7866666666666667, 'eval_runtime': 1.5502, 'eval_samples_per_second': 3.225, 'eval_steps_per_second': 3.225, 'epoch': 7.0}\n",
      "{'loss': 0.6604, 'grad_norm': 4.71323823928833, 'learning_rate': 1.2e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea492a48b447a0adeb62a1e4f40fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6383451223373413, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.5553, 'eval_samples_per_second': 3.215, 'eval_steps_per_second': 3.215, 'epoch': 8.0}\n",
      "{'loss': 0.5119, 'grad_norm': 9.498541831970215, 'learning_rate': 1.1000000000000001e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4caded268b84853a126abec6f3b19cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5073884129524231, 'eval_accuracy': 0.8, 'eval_f1': 0.7866666666666667, 'eval_runtime': 1.5824, 'eval_samples_per_second': 3.16, 'eval_steps_per_second': 3.16, 'epoch': 9.0}\n",
      "{'loss': 0.3568, 'grad_norm': 7.109187126159668, 'learning_rate': 1e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74fe12aec13424b901d2307a8866625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36598625779151917, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 2.1129, 'eval_samples_per_second': 2.366, 'eval_steps_per_second': 2.366, 'epoch': 10.0}\n",
      "{'loss': 0.239, 'grad_norm': 9.488040924072266, 'learning_rate': 9e-06, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0e256875014511b1804b5dc73b8486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3182787299156189, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.6265, 'eval_samples_per_second': 3.074, 'eval_steps_per_second': 3.074, 'epoch': 11.0}\n",
      "{'loss': 0.1794, 'grad_norm': 1.4582124948501587, 'learning_rate': 8.000000000000001e-06, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb50f813bef34d1fb114e6c8eb449fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17570318281650543, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.572, 'eval_samples_per_second': 3.181, 'eval_steps_per_second': 3.181, 'epoch': 12.0}\n",
      "{'loss': 0.136, 'grad_norm': 3.279721975326538, 'learning_rate': 7e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b65beed0c6453b914d51116c613cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14755988121032715, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.5824, 'eval_samples_per_second': 3.16, 'eval_steps_per_second': 3.16, 'epoch': 13.0}\n",
      "{'loss': 0.1012, 'grad_norm': 0.5643743872642517, 'learning_rate': 6e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009ef104b32e451ab3a24b43185ab67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11887383460998535, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 2.0641, 'eval_samples_per_second': 2.422, 'eval_steps_per_second': 2.422, 'epoch': 14.0}\n",
      "{'loss': 0.0778, 'grad_norm': 2.0376741886138916, 'learning_rate': 5e-06, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c25f43fcbc4f4a9b1ea3e6ea743507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09653078019618988, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.6067, 'eval_samples_per_second': 3.112, 'eval_steps_per_second': 3.112, 'epoch': 15.0}\n",
      "{'loss': 0.0729, 'grad_norm': 2.0203943252563477, 'learning_rate': 4.000000000000001e-06, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1323e4914fff44029f22225dc51fb1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08449219167232513, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.6035, 'eval_samples_per_second': 3.118, 'eval_steps_per_second': 3.118, 'epoch': 16.0}\n",
      "{'loss': 0.0552, 'grad_norm': 1.6369279623031616, 'learning_rate': 3e-06, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5572ca343b7a4ffc9080eb54077cf1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07239826768636703, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.5875, 'eval_samples_per_second': 3.15, 'eval_steps_per_second': 3.15, 'epoch': 17.0}\n",
      "{'loss': 0.0519, 'grad_norm': 1.3551231622695923, 'learning_rate': 2.0000000000000003e-06, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a67f2edec249b8afdd6b7f7e79c596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06682656705379486, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.5691, 'eval_samples_per_second': 3.187, 'eval_steps_per_second': 3.187, 'epoch': 18.0}\n",
      "{'loss': 0.0472, 'grad_norm': 0.390796959400177, 'learning_rate': 1.0000000000000002e-06, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b43c4e74b9465d825c7e40f042e9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06221116706728935, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.535, 'eval_samples_per_second': 3.257, 'eval_steps_per_second': 3.257, 'epoch': 19.0}\n",
      "{'loss': 0.0552, 'grad_norm': 0.6928702592849731, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba422b1a57e54b209f9726a18e5f93ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06124318763613701, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 1.5904, 'eval_samples_per_second': 3.144, 'eval_steps_per_second': 3.144, 'epoch': 20.0}\n",
      "{'train_runtime': 300.269, 'train_samples_per_second': 0.666, 'train_steps_per_second': 0.666, 'train_loss': 0.49187826544046404, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.49187826544046404, metrics={'train_runtime': 300.269, 'train_samples_per_second': 0.666, 'train_steps_per_second': 0.666, 'total_flos': 17593640136000.0, 'train_loss': 0.49187826544046404, 'epoch': 20.0})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "logging_steps = len(dataset_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=20,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False, \n",
    "                                  log_level=\"error\")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=dataset_encoded[\"train\"],\n",
    "                  eval_dataset=dataset_encoded[\"test\"],\n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "# Now you can train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/DistilBertForSequenceClassification_finetune\\\\tokenizer_config.json',\n",
       " './models/DistilBertForSequenceClassification_finetune\\\\special_tokens_map.json',\n",
       " './models/DistilBertForSequenceClassification_finetune\\\\vocab.txt',\n",
       " './models/DistilBertForSequenceClassification_finetune\\\\added_tokens.json')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./models/DistilBertForSequenceClassification_finetune\")\n",
    "tokenizer.save_pretrained(\"./models/DistilBertForSequenceClassification_finetune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model and tokenizer for classification\n",
    "model_name = \"./models/DistilBertForSequenceClassification_finetune\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model, tokenizer):\n",
    "    # Tokenize the input texts\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Pass inputs through the model to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    # Get the embeddings from the last hidden state\n",
    "    hidden_states = outputs.hidden_states[-1]\n",
    "    # Average the hidden states to get a single vector representation for each text\n",
    "    embeddings = hidden_states.mean(dim=1)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract texts from the dictionary\n",
    "texts = list(extracted_content.values())\n",
    "\n",
    "# Get embeddings for all documents\n",
    "embeddings = get_embeddings(texts, model, tokenizer)\n",
    "\n",
    "# Compute cosine similarity between all pairs of embeddings\n",
    "cosine_similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Convert cosine similarity matrix to a DataFrame\n",
    "doc_keys = list(extracted_content.keys())\n",
    "cosine_sim_df = pd.DataFrame(cosine_similarities, index=doc_keys, columns=doc_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>34944_高鐵_促參.pdf</th>\n",
       "      <th>38005_核四_政策.pdf</th>\n",
       "      <th>39243_核四_品質.pdf</th>\n",
       "      <th>39477_核四_料件.pdf</th>\n",
       "      <th>46365_高鐵_基金.pdf</th>\n",
       "      <th>48052_大客車_逃生門.pdf</th>\n",
       "      <th>48746_大客車_安全門.pdf</th>\n",
       "      <th>49490_核四_延宕.pdf</th>\n",
       "      <th>49627_核四_停建.pdf</th>\n",
       "      <th>49676_大客車_駕照.pdf</th>\n",
       "      <th>52922_大客車_超時.pdf</th>\n",
       "      <th>54210_高鐵_出資.pdf</th>\n",
       "      <th>54376_高鐵_航發.pdf</th>\n",
       "      <th>54561_高鐵_機電.pdf</th>\n",
       "      <th>58930_核四_封存.pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34944_高鐵_促參.pdf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417318</td>\n",
       "      <td>0.307828</td>\n",
       "      <td>0.298110</td>\n",
       "      <td>0.904093</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>0.391825</td>\n",
       "      <td>0.355231</td>\n",
       "      <td>0.314579</td>\n",
       "      <td>0.470008</td>\n",
       "      <td>0.400194</td>\n",
       "      <td>0.841870</td>\n",
       "      <td>0.917164</td>\n",
       "      <td>0.920596</td>\n",
       "      <td>0.302345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38005_核四_政策.pdf</th>\n",
       "      <td>0.417318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930923</td>\n",
       "      <td>0.934776</td>\n",
       "      <td>0.378236</td>\n",
       "      <td>0.333038</td>\n",
       "      <td>0.340692</td>\n",
       "      <td>0.934884</td>\n",
       "      <td>0.935140</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>0.319154</td>\n",
       "      <td>0.625760</td>\n",
       "      <td>0.429262</td>\n",
       "      <td>0.387953</td>\n",
       "      <td>0.947258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243_核四_品質.pdf</th>\n",
       "      <td>0.307828</td>\n",
       "      <td>0.930923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>0.266039</td>\n",
       "      <td>0.297337</td>\n",
       "      <td>0.296697</td>\n",
       "      <td>0.963850</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.265987</td>\n",
       "      <td>0.279806</td>\n",
       "      <td>0.515793</td>\n",
       "      <td>0.310987</td>\n",
       "      <td>0.291609</td>\n",
       "      <td>0.959369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39477_核四_料件.pdf</th>\n",
       "      <td>0.298110</td>\n",
       "      <td>0.934776</td>\n",
       "      <td>0.970819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250550</td>\n",
       "      <td>0.255173</td>\n",
       "      <td>0.261974</td>\n",
       "      <td>0.973752</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.236424</td>\n",
       "      <td>0.245618</td>\n",
       "      <td>0.511841</td>\n",
       "      <td>0.312808</td>\n",
       "      <td>0.280154</td>\n",
       "      <td>0.980898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46365_高鐵_基金.pdf</th>\n",
       "      <td>0.904093</td>\n",
       "      <td>0.378236</td>\n",
       "      <td>0.266039</td>\n",
       "      <td>0.250550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276737</td>\n",
       "      <td>0.240118</td>\n",
       "      <td>0.304128</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>0.302538</td>\n",
       "      <td>0.247362</td>\n",
       "      <td>0.756903</td>\n",
       "      <td>0.940067</td>\n",
       "      <td>0.927004</td>\n",
       "      <td>0.268291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48052_大客車_逃生門.pdf</th>\n",
       "      <td>0.420610</td>\n",
       "      <td>0.333038</td>\n",
       "      <td>0.297337</td>\n",
       "      <td>0.255173</td>\n",
       "      <td>0.276737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957067</td>\n",
       "      <td>0.299197</td>\n",
       "      <td>0.263307</td>\n",
       "      <td>0.946254</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>0.286807</td>\n",
       "      <td>0.311274</td>\n",
       "      <td>0.254030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48746_大客車_安全門.pdf</th>\n",
       "      <td>0.391825</td>\n",
       "      <td>0.340692</td>\n",
       "      <td>0.296697</td>\n",
       "      <td>0.261974</td>\n",
       "      <td>0.240118</td>\n",
       "      <td>0.957067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310364</td>\n",
       "      <td>0.272421</td>\n",
       "      <td>0.956717</td>\n",
       "      <td>0.973044</td>\n",
       "      <td>0.511702</td>\n",
       "      <td>0.262522</td>\n",
       "      <td>0.269896</td>\n",
       "      <td>0.259872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49490_核四_延宕.pdf</th>\n",
       "      <td>0.355231</td>\n",
       "      <td>0.934884</td>\n",
       "      <td>0.963850</td>\n",
       "      <td>0.973752</td>\n",
       "      <td>0.304128</td>\n",
       "      <td>0.299197</td>\n",
       "      <td>0.310364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983293</td>\n",
       "      <td>0.288714</td>\n",
       "      <td>0.292697</td>\n",
       "      <td>0.576746</td>\n",
       "      <td>0.363071</td>\n",
       "      <td>0.322874</td>\n",
       "      <td>0.959255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49627_核四_停建.pdf</th>\n",
       "      <td>0.314579</td>\n",
       "      <td>0.935140</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>0.263307</td>\n",
       "      <td>0.272421</td>\n",
       "      <td>0.983293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.255632</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.330533</td>\n",
       "      <td>0.293379</td>\n",
       "      <td>0.981257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49676_大客車_駕照.pdf</th>\n",
       "      <td>0.470008</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>0.265987</td>\n",
       "      <td>0.236424</td>\n",
       "      <td>0.302538</td>\n",
       "      <td>0.946254</td>\n",
       "      <td>0.956717</td>\n",
       "      <td>0.288714</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963470</td>\n",
       "      <td>0.548796</td>\n",
       "      <td>0.333955</td>\n",
       "      <td>0.331156</td>\n",
       "      <td>0.233175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52922_大客車_超時.pdf</th>\n",
       "      <td>0.400194</td>\n",
       "      <td>0.319154</td>\n",
       "      <td>0.279806</td>\n",
       "      <td>0.245618</td>\n",
       "      <td>0.247362</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.973044</td>\n",
       "      <td>0.292697</td>\n",
       "      <td>0.255632</td>\n",
       "      <td>0.963470</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.263396</td>\n",
       "      <td>0.279084</td>\n",
       "      <td>0.242160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54210_高鐵_出資.pdf</th>\n",
       "      <td>0.841870</td>\n",
       "      <td>0.625760</td>\n",
       "      <td>0.515793</td>\n",
       "      <td>0.511841</td>\n",
       "      <td>0.756903</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>0.511702</td>\n",
       "      <td>0.576746</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.548796</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>0.765792</td>\n",
       "      <td>0.506139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54376_高鐵_航發.pdf</th>\n",
       "      <td>0.917164</td>\n",
       "      <td>0.429262</td>\n",
       "      <td>0.310987</td>\n",
       "      <td>0.312808</td>\n",
       "      <td>0.940067</td>\n",
       "      <td>0.286807</td>\n",
       "      <td>0.262522</td>\n",
       "      <td>0.363071</td>\n",
       "      <td>0.330533</td>\n",
       "      <td>0.333955</td>\n",
       "      <td>0.263396</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913697</td>\n",
       "      <td>0.326501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54561_高鐵_機電.pdf</th>\n",
       "      <td>0.920596</td>\n",
       "      <td>0.387953</td>\n",
       "      <td>0.291609</td>\n",
       "      <td>0.280154</td>\n",
       "      <td>0.927004</td>\n",
       "      <td>0.311274</td>\n",
       "      <td>0.269896</td>\n",
       "      <td>0.322874</td>\n",
       "      <td>0.293379</td>\n",
       "      <td>0.331156</td>\n",
       "      <td>0.279084</td>\n",
       "      <td>0.765792</td>\n",
       "      <td>0.913697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58930_核四_封存.pdf</th>\n",
       "      <td>0.302345</td>\n",
       "      <td>0.947258</td>\n",
       "      <td>0.959369</td>\n",
       "      <td>0.980898</td>\n",
       "      <td>0.268291</td>\n",
       "      <td>0.254030</td>\n",
       "      <td>0.259872</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.981257</td>\n",
       "      <td>0.233175</td>\n",
       "      <td>0.242160</td>\n",
       "      <td>0.506139</td>\n",
       "      <td>0.326501</td>\n",
       "      <td>0.290121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   34944_高鐵_促參.pdf  38005_核四_政策.pdf  39243_核四_品質.pdf  \\\n",
       "34944_高鐵_促參.pdf           1.000000         0.417318         0.307828   \n",
       "38005_核四_政策.pdf           0.417318         1.000000         0.930923   \n",
       "39243_核四_品質.pdf           0.307828         0.930923         1.000000   \n",
       "39477_核四_料件.pdf           0.298110         0.934776         0.970819   \n",
       "46365_高鐵_基金.pdf           0.904093         0.378236         0.266039   \n",
       "48052_大客車_逃生門.pdf         0.420610         0.333038         0.297337   \n",
       "48746_大客車_安全門.pdf         0.391825         0.340692         0.296697   \n",
       "49490_核四_延宕.pdf           0.355231         0.934884         0.963850   \n",
       "49627_核四_停建.pdf           0.314579         0.935140         0.964964   \n",
       "49676_大客車_駕照.pdf          0.470008         0.323404         0.265987   \n",
       "52922_大客車_超時.pdf          0.400194         0.319154         0.279806   \n",
       "54210_高鐵_出資.pdf           0.841870         0.625760         0.515793   \n",
       "54376_高鐵_航發.pdf           0.917164         0.429262         0.310987   \n",
       "54561_高鐵_機電.pdf           0.920596         0.387953         0.291609   \n",
       "58930_核四_封存.pdf           0.302345         0.947258         0.959369   \n",
       "\n",
       "                   39477_核四_料件.pdf  46365_高鐵_基金.pdf  48052_大客車_逃生門.pdf  \\\n",
       "34944_高鐵_促參.pdf           0.298110         0.904093           0.420610   \n",
       "38005_核四_政策.pdf           0.934776         0.378236           0.333038   \n",
       "39243_核四_品質.pdf           0.970819         0.266039           0.297337   \n",
       "39477_核四_料件.pdf           1.000000         0.250550           0.255173   \n",
       "46365_高鐵_基金.pdf           0.250550         1.000000           0.276737   \n",
       "48052_大客車_逃生門.pdf         0.255173         0.276737           1.000000   \n",
       "48746_大客車_安全門.pdf         0.261974         0.240118           0.957067   \n",
       "49490_核四_延宕.pdf           0.973752         0.304128           0.299197   \n",
       "49627_核四_停建.pdf           0.990394         0.265703           0.263307   \n",
       "49676_大客車_駕照.pdf          0.236424         0.302538           0.946254   \n",
       "52922_大客車_超時.pdf          0.245618         0.247362           0.959144   \n",
       "54210_高鐵_出資.pdf           0.511841         0.756903           0.499668   \n",
       "54376_高鐵_航發.pdf           0.312808         0.940067           0.286807   \n",
       "54561_高鐵_機電.pdf           0.280154         0.927004           0.311274   \n",
       "58930_核四_封存.pdf           0.980898         0.268291           0.254030   \n",
       "\n",
       "                   48746_大客車_安全門.pdf  49490_核四_延宕.pdf  49627_核四_停建.pdf  \\\n",
       "34944_高鐵_促參.pdf             0.391825         0.355231         0.314579   \n",
       "38005_核四_政策.pdf             0.340692         0.934884         0.935140   \n",
       "39243_核四_品質.pdf             0.296697         0.963850         0.964964   \n",
       "39477_核四_料件.pdf             0.261974         0.973752         0.990394   \n",
       "46365_高鐵_基金.pdf             0.240118         0.304128         0.265703   \n",
       "48052_大客車_逃生門.pdf           0.957067         0.299197         0.263307   \n",
       "48746_大客車_安全門.pdf           1.000000         0.310364         0.272421   \n",
       "49490_核四_延宕.pdf             0.310364         1.000000         0.983293   \n",
       "49627_核四_停建.pdf             0.272421         0.983293         1.000000   \n",
       "49676_大客車_駕照.pdf            0.956717         0.288714         0.248927   \n",
       "52922_大客車_超時.pdf            0.973044         0.292697         0.255632   \n",
       "54210_高鐵_出資.pdf             0.511702         0.576746         0.525015   \n",
       "54376_高鐵_航發.pdf             0.262522         0.363071         0.330533   \n",
       "54561_高鐵_機電.pdf             0.269896         0.322874         0.293379   \n",
       "58930_核四_封存.pdf             0.259872         0.959255         0.981257   \n",
       "\n",
       "                   49676_大客車_駕照.pdf  52922_大客車_超時.pdf  54210_高鐵_出資.pdf  \\\n",
       "34944_高鐵_促參.pdf            0.470008          0.400194         0.841870   \n",
       "38005_核四_政策.pdf            0.323404          0.319154         0.625760   \n",
       "39243_核四_品質.pdf            0.265987          0.279806         0.515793   \n",
       "39477_核四_料件.pdf            0.236424          0.245618         0.511841   \n",
       "46365_高鐵_基金.pdf            0.302538          0.247362         0.756903   \n",
       "48052_大客車_逃生門.pdf          0.946254          0.959144         0.499668   \n",
       "48746_大客車_安全門.pdf          0.956717          0.973044         0.511702   \n",
       "49490_核四_延宕.pdf            0.288714          0.292697         0.576746   \n",
       "49627_核四_停建.pdf            0.248927          0.255632         0.525015   \n",
       "49676_大客車_駕照.pdf           1.000000          0.963470         0.548796   \n",
       "52922_大客車_超時.pdf           0.963470          0.999999         0.500650   \n",
       "54210_高鐵_出資.pdf            0.548796          0.500650         1.000000   \n",
       "54376_高鐵_航發.pdf            0.333955          0.263396         0.822496   \n",
       "54561_高鐵_機電.pdf            0.331156          0.279084         0.765792   \n",
       "58930_核四_封存.pdf            0.233175          0.242160         0.506139   \n",
       "\n",
       "                   54376_高鐵_航發.pdf  54561_高鐵_機電.pdf  58930_核四_封存.pdf  \n",
       "34944_高鐵_促參.pdf           0.917164         0.920596         0.302345  \n",
       "38005_核四_政策.pdf           0.429262         0.387953         0.947258  \n",
       "39243_核四_品質.pdf           0.310987         0.291609         0.959369  \n",
       "39477_核四_料件.pdf           0.312808         0.280154         0.980898  \n",
       "46365_高鐵_基金.pdf           0.940067         0.927004         0.268291  \n",
       "48052_大客車_逃生門.pdf         0.286807         0.311274         0.254030  \n",
       "48746_大客車_安全門.pdf         0.262522         0.269896         0.259872  \n",
       "49490_核四_延宕.pdf           0.363071         0.322874         0.959255  \n",
       "49627_核四_停建.pdf           0.330533         0.293379         0.981257  \n",
       "49676_大客車_駕照.pdf          0.333955         0.331156         0.233175  \n",
       "52922_大客車_超時.pdf          0.263396         0.279084         0.242160  \n",
       "54210_高鐵_出資.pdf           0.822496         0.765792         0.506139  \n",
       "54376_高鐵_航發.pdf           1.000000         0.913697         0.326501  \n",
       "54561_高鐵_機電.pdf           0.913697         1.000000         0.290121  \n",
       "58930_核四_封存.pdf           0.326501         0.290121         1.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52922_大客車_超時.pdf     0.999999\n",
       "48746_大客車_安全門.pdf    0.973044\n",
       "49676_大客車_駕照.pdf     0.963470\n",
       "48052_大客車_逃生門.pdf    0.959144\n",
       "54210_高鐵_出資.pdf      0.500650\n",
       "34944_高鐵_促參.pdf      0.400194\n",
       "38005_核四_政策.pdf      0.319154\n",
       "49490_核四_延宕.pdf      0.292697\n",
       "39243_核四_品質.pdf      0.279806\n",
       "54561_高鐵_機電.pdf      0.279084\n",
       "54376_高鐵_航發.pdf      0.263396\n",
       "49627_核四_停建.pdf      0.255632\n",
       "46365_高鐵_基金.pdf      0.247362\n",
       "39477_核四_料件.pdf      0.245618\n",
       "58930_核四_封存.pdf      0.242160\n",
       "Name: 52922_大客車_超時.pdf, dtype: float32"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_df['52922_大客車_超時.pdf'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.to_csv(f'cos_similarity_{model_ckpt}.csv', encoding='big5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paraphrase-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-0.2189,  0.8674,  0.4606,  ..., -0.6580, -0.4033,  0.6827],\n",
      "        [ 0.0677,  0.7340,  0.7409,  ..., -0.4495, -0.2585,  0.5965],\n",
      "        [-0.5176,  0.7155,  0.3799,  ..., -0.7914, -0.3436,  0.7034],\n",
      "        ...,\n",
      "        [-0.0959,  0.8173,  0.6737,  ..., -0.6921, -0.6189,  0.6678],\n",
      "        [-0.2214,  0.6630,  0.3330,  ..., -0.8624,  0.2184,  0.6604],\n",
      "        [ 0.0169,  0.9363,  0.4728,  ..., -0.5107, -0.2639,  0.6777]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = list(extracted_content.values())\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, max pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_keys = list(extracted_content.keys())\n",
    "cosine_sim_df = pd.DataFrame(cosine_similarities, index=doc_keys, columns=doc_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48052_大客車_逃生門.pdf    1.000000\n",
       "39243_核四_品質.pdf      0.949153\n",
       "54561_高鐵_機電.pdf      0.939176\n",
       "46365_高鐵_基金.pdf      0.906380\n",
       "34944_高鐵_促參.pdf      0.888729\n",
       "52922_大客車_超時.pdf     0.878784\n",
       "39477_核四_料件.pdf      0.874396\n",
       "49676_大客車_駕照.pdf     0.863293\n",
       "54376_高鐵_航發.pdf      0.849896\n",
       "49627_核四_停建.pdf      0.848142\n",
       "54210_高鐵_出資.pdf      0.836646\n",
       "49490_核四_延宕.pdf      0.791983\n",
       "58930_核四_封存.pdf      0.791870\n",
       "38005_核四_政策.pdf      0.789064\n",
       "48746_大客車_安全門.pdf    0.784512\n",
       "Name: 48052_大客車_逃生門.pdf, dtype: float32"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_df['48052_大客車_逃生門.pdf'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'34944_高鐵_促參.pdf': '交通部於 87年間與臺灣高速鐵路公司簽訂「臺灣南北高速鐵路興建營運合約」及「臺灣南北高速鐵路站區開發合約 」，疏未預先審度該公司展延高鐵通車營運時程及遲延受領站區用地所生 損失之責任歸屬，並綢繆約定 相關處罰條款 ，嗣對政府權益保障恝置不察，一再同意該公司展延通車營運時程及受領站區用地， 致政府蒙受回饋金與租金收入減少及顧問費用增加等鉅額損失，均有違失，爰依監察法第 24條規定提案糾正',\n",
       " '38005_核四_政策.pdf': '核四封存後每年仍耗費數億元於資產維護管理，行政院及經濟部對外宣告核四重啟不可行，核四興建費用 2,833億元頇列為損失，行政院及 經濟部對核四政策之重大變動，導致資源嚴重浪費； 再者，經濟部宣布能源配比 (燃氣50%、燃煤30%、再生能源20%)之能源轉型政策，未經能源安全、能源經濟及環境影響等完整評估 ，復於再生能源發電量增加有限情況下， 以運轉中核電機組長期停機 方式減核 ，致近年火力發購電量逐年提高， 106年占比達84.4%，燃煤發電增幅 甚至高於燃氣，造成嚴重空氣污染；以及經濟部宣布 新能源政策 之前，並未評估其對電價之影響，迄 106年3月行政院始於國公營企業體檢小組會議評估 等情，均有違失，爰依法提案糾正',\n",
       " '39243_核四_品質.pdf': '台電公司 未落實「核四工程品質保證方案」，致龍門電廠試運轉時違規與注意改善事項層出不窮，如 抑壓池灌水作業 不當，致反應器廠房底層淹水 、壓力試驗合格之室內消防栓 系統，其 太平龍頭 竟脫落，致汽機廠房積水等 ，均嚴重衝擊國人對核能安全運轉之信心等情 ，確有諸多違失，爰依法提案糾正',\n",
       " '39477_核四_料件.pdf': '台灣電力股份有限公司 (下稱台電公司 )於本院調查核四廠一號機因施工測詴期間設備損壞而移用二號機相關設備之過程，所提供資料內容前後不一，設備組件損壞、採購及修復個數未能確實清查正確，顯見台電公司核四廠之料件管理系統紊亂，且回復本院公文一再發生資料正確性不足，核有怠失；另台電公司於 81年陳報核四興建計畫， 竟以69年所估算成本陳報， 未能如實報告核四建廠成本，致使政府無法確實評估該項投資計畫之成本效益，台電公司表示當時即考慮日後再以追加預算方式提出，此亦導致政 府長年來不得不對核四預算持續加碼，形成台電公司及國家之財務負擔，核有違失，爰依法提案糾正',\n",
       " '46365_高鐵_基金.pdf': '近年利率逐年下調， 資金成本下降， 惟交通部未督飭高公局利用此 改變趨勢而進行財務調度，積極規劃國道基金債務之舉新還舊，減輕利息 負擔，改善財務結構 ；該部復坐視國道基金之財務操作 受高鐵基金之影響；又該部迄今未將 國道基金負擔 未具自償性且與國道並無直接關聯之地區性道路興建支出，撥還該基金等情，均核有重大違失，爰依法提案糾正',\n",
       " '48052_大客車_逃生門.pdf': '交通部暨公路總局未善盡監督及執行車輛之監理機制，輕縱尊龍客運等公司違規變更內裝而危害公共安全，致生本案大客車六名乘客因逃生門遭鐵板封閉，無法開啟而慘遭大火燒死之重大事故，顯有違失，爰依監察法第二十四條之規定提案糾正',\n",
       " '48746_大客車_安全門.pdf': '交通部核准之安審（ 98）第1620號車型大客車，其檢測報告判定緊急出口符合法規，得於車輛靜止時由車內及車外徒手開啟，然105年7月19日（下稱0719）陸客團火燒車事故發生時卻因遊覽車左側安全門掛有鐵鍊並未即時開啟，其相同型式 20部車輛經查核亦逾八成於安全門裝置暗鎖，業嚴重威脅乘客逃生機會 ；又該部於核發車輛型式安全審驗合格證明書後，未善盡監督車身打造廠依法落實執行品質一致性管制計畫書，無法確保大客車之安全品質具有一致性 ；復漠視國內遊覽車業者為增設原廠設計所無之相關配備，擅自變更底盤電路系統，新核定之大客車電氣設備審驗補充作業規定 亦未包含使用中之舊車型大客車，恐難避免使用中之遊覽車車輛電路系統因加裝施工不良或過度負荷引發火災之可能性，造成人民生命財產之嚴重危害， 確有重大違失，爰依法提案糾正',\n",
       " '49490_核四_延宕.pdf': '台灣電力股份有限公司辦理核四計畫， 未採統包模式 ，衍生各類採購標案多達 835項，界面 整合困難， 且怠忽控管顧問公司工作內容，肇致服務費用暴增卻無法依約完成工作 ，又在未取得關鍵外購設備細部規格前，竟同意承商以假設數據先行設計，致到貨後頇 額外補償 修改變更費用 ，加上工地防颱應變失當等諸多違失，導致計畫執行效能不彰，進度嚴重落後，商轉日期一再展延逾 11年迄仍無著，工程經費更由新台幣 1,697億餘元暴增至 2,736億餘元，增幅超過 6成達1,039億餘元，且後續增加勢必難免，斲喪國家利益與政府形象；經濟部為核四計畫執行督導機關，長期粉飾計畫執行遭遇之瓶頸癥結，未能積極督飭台電公司有效因應妥處，恝置履約爭議及施工管理問題層出不窮，亦難辭怠忽監督之咎',\n",
       " '49627_核四_停建.pdf': '行政院貿然於 89年10月27日宣布停建進度已達33.81%之核四工程，又經濟部對於臺電公司三度函詢核四停建相關疑義，卻一再模糊虛應，恝置所屬無所適從，另臺電公司為迎合上意，未待上級正式函示或召開董事會應變，即由公司高層僅以口諭方式擅為傳達停建核四，並倉促發函指示廠商 不限期暫停契約執行，且核四工程未能採統包方式辦理，亦未有總顧問協助整合複雜之施工界面，導致工期延宕、預算追加、鉅額損失及品質安全疑慮等情事，其工期至少增加 44個月，且損失高達 1,870億元，未來核四是否安全運轉，屢遭質疑， 且現已逾核四計畫一號機展延後 之預訂商轉日期，惟尚未見修訂計畫期程， 行政院暨所屬經濟部、臺電公司等均難辭其咎',\n",
       " '49676_大客車_駕照.pdf': '交通部公路總局 辦理遊覽車客運業營運管理考核業務， 怠未督促所屬落實 各項表件查核勾稽職責，縱任 世通遊覽車客運股份有限公司 長期僱用無大客車職業駕駛執照者駕駛遊覽車，未 能及時查處 並責令改正，肇生101年5月9日花蓮太魯閣錦文橋旁翻車事故，嚴重危害旅運安全；且該局派赴事故現場人員，竟未查知該 翻覆遊覽車未依規定隨車攜帶駕駛人登記證、派車單及租車契約等資料，迨本院約詢通知責請說明後，始急洽業者查證屬實，並依違反汽車運輸業管理規則補行罰款，確有怠失，爰依法提案糾正',\n",
       " '52922_大客車_超時.pdf': '勞委會辦理公路客運業司機工時稽查，長久坐視超時工作之嚴重性，僅就稽查結果轉送各地勞政單位裁罰，對後續執行及改善措施未能落實追蹤管考，輕忽該行業攸關公眾安全之特性 ；交通部未能參酌先進國家對公路客運業合理駕駛時間之制訂，復未對近年因疲勞駕駛之肇禍事件深切檢討，以訂定公路客運業司機合理駕駛時間；公路總局於執行大客車駕駛審驗措施，未能記取近年發生多次公路客運業司機因個人健康因素，中斷行車任務之教訓，訂定妥適之健檢項目與標準 ，均核有違失',\n",
       " '54210_高鐵_出資.pdf': '行政院明知高鐵公司籌資不順，財務困難，投資風險極高，不但未能督促原始股東履行「政府零出資」承諾，反而 准予所屬公營事業機構、或實質上受其控制之公私合營公司或政府捐助財團法人將資金投入該公司一再挹注該公司鉅額資金 ，復提供鉅額中長期資金及融資保證，不但危及政府財政，並以公權力牽拖耗喪社會資材，嚴重悖離 BOT基本精神另中鋼公司投資高鐵公司特別股，該公司董事長林 ○○不但同時兼任高鐵公司董事，並三次主導投資高鐵公司特別股，立場偏失，主管機關皆怠忽不察；中技社投資高鐵公司特別股，既不合原捐助目的及章程規定，且程序上亦有重大瑕疵，復影響該社財務資金運用甚鉅，主管機關經濟部皆恝置不理又 財政部甫 修正相關法令，各公營及公私 合營行庫旋即投資高鐵公司計一百七十三億元，招致非議；公營行庫將上開投資不當認列為短期投資，不僅傷及公營行庫財務表達之正確性，且得以短期投資拖延補辦預算之程序；高鐵公司財務狀況日趨惡化，政府財務擔保風險持續升高，交通部長期視若無睹，粉飾太帄，徒增政府財務風險，均有重大違失 ，爰依法提案糾正',\n",
       " '54376_高鐵_航發.pdf': '行政院為協助解決臺灣高速鐵路公司 (下稱高鐵公司 )資金需求，指示中華航空事業發展基金會 (下稱航發會 )限期購買該公司丙種特別股新臺幣 (下同 )四十五億元，惟該項投資決策未經正式會議及評估作業，亦未留存任何紀錄可供稽查，過程粗糙急率；又該院明知航發會屬財團法人，投資高速鐵路有違該會 協助發展航空事業之章程目的，亦可知悉因時間急迫，相關董事會召集程序勢難符合法令規定，仍為上開違反章程及法令之指示，顯有失當；而交通部長擔任航發會董事長，管理及監督財團法人之角色混同，董事會以遵守政策指示及考量國家利益為由通過相關議案，交通部復怠於監督，率予許可，致生航發會重大損害，財團法人設置之公益目的盪然無存，爰依法提案糾正',\n",
       " '54561_高鐵_機電.pdf': '交通部及所屬高速鐵路工程局 率爾同意 變更機電核心系統，致 台灣高鐵淪為歐、日混血系統，每百萬公里發生之行車事故件數，較日本新幹線高出甚多，迄未深入檢討等情，爰依法提案糾正',\n",
       " '58930_核四_封存.pdf': '我國核能安全監管機關為行政院原子能委員會，核四未經該會完整審查認可，未符合核能安全要求 下，經濟部卻以核四安檢過關，使部分民眾認 為核四安全已由經濟部審查掛保證通過， 積非成是，影響迄今；而核四封存前， 未能解決 諸多系統 之設計及設備問題，即使當時並未封存、繼續詴運轉下去，仍有安全疑慮， 在外界對於核四重啟見解不一之際， 經濟部反而提供錯誤訊息 ，導致核四紛擾不斷又，台電未能及時監督承商， 現因核四斷層新事證，更加劇後續處理之困難度，台電對核能安全與核四品質把關 之相關作為，確實不夠嚴謹， 經濟部及台電均 核有怠失，爰依法提案糾正'}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervisor_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
